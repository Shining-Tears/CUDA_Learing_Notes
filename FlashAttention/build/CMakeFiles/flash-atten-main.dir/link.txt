/usr/bin/c++  -D_GLIBCXX_USE_CXX11_ABI=1 -g CMakeFiles/flash-atten-main.dir/main.cpp.o CMakeFiles/flash-atten-main.dir/flash-attention-v1.cu.o -o flash-atten-main   -L/lib/intel64  -L/lib/intel64_win  -L/lib/win-x64  -L/usr/local/cuda-12.8/targets/x86_64-linux/lib/stubs  -L/usr/local/cuda-12.8/targets/x86_64-linux/lib  -Wl,-rpath,/lib/intel64:/lib/intel64_win:/lib/win-x64:/home/wenze/source/FlashAttention/libtorch/lib:/usr/local/cuda-12.8/lib64 ../libtorch/lib/libtorch.so ../libtorch/lib/libc10.so ../libtorch/lib/libkineto.a /usr/local/cuda-12.8/lib64/libnvrtc.so ../libtorch/lib/libc10_cuda.so -Wl,--no-as-needed,"/home/wenze/source/FlashAttention/libtorch/lib/libtorch_cpu.so" -Wl,--as-needed -Wl,--no-as-needed,"/home/wenze/source/FlashAttention/libtorch/lib/libtorch_cuda.so" -Wl,--as-needed ../libtorch/lib/libc10_cuda.so ../libtorch/lib/libc10.so /usr/local/cuda-12.8/lib64/libcudart.so -Wl,--no-as-needed,"/home/wenze/source/FlashAttention/libtorch/lib/libtorch.so" -Wl,--as-needed /usr/local/cuda-12.8/lib64/libnvToolsExt.so -lcudadevrt -lcudart_static -lrt -lpthread -ldl 
